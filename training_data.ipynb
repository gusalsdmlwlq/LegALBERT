{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"data/training_data.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = f.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6138630"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tokenizers import BertWordPieceTokenizer\n",
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = BertWordPieceTokenizer(\"assets/kor-vocab.txt\", lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_data = []\n",
    "num_tokens = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_token_length = 5\n",
    "max_token_length = 510"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):    \n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    text = text.replace(\". \", \".\")\n",
    "    text = re.sub(r\"([ㄱ-ㅎㅏ-ㅣ가-힣])\\.([\\S])\", r\"\\1. \\2\", text)\n",
    "    text = re.sub(r\"([\\S])\\.([ㄱ-ㅎㅏ-ㅣ가-힣])\", r\"\\1. \\2\", text)\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6138630/6138630 [1:21:26<00:00, 1256.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4898.969509601593\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "start = time.time()\n",
    "for row in tqdm(data, total=len(data)):\n",
    "    tokens = []\n",
    "    if len(tokenizer.encode(row, add_special_tokens=False).ids) <= min_token_length:\n",
    "        continue\n",
    "    sentences = sent_tokenize(row)\n",
    "    for sent in sentences:\n",
    "        tokens_ = tokenizer.encode(sent, add_special_tokens=False).ids\n",
    "        if len(tokens) + len(tokens_) <= max_token_length:\n",
    "            tokens += tokens_\n",
    "        else:\n",
    "            new_data.append(clean_text(tokenizer.decode(tokens)))\n",
    "            num_tokens += len(tokens)\n",
    "            tokens = tokens_[:max_token_length]\n",
    "    new_data.append(clean_text(tokenizer.decode(tokens)))\n",
    "    num_tokens += len(tokens)\n",
    "    tokens = []\n",
    "with open(\"data/training_data_processed.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for row in new_data:\n",
    "        f.write(row+\"\\n\")\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "433555207"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6138630"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5559355"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = open(\"data/training_data_processed.txt\", \"r\").read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(1)\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"data/train_data.txt\", \"w\") as f:\n",
    "    for row in data[:-]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['짜식, 힘내! 우린, 한국의 아이들이잖아! 그래. 고맙다. 처음 만난 사인데 별 얘길 다하네. 이상하게 나도 너 첨 볼 때부터 않고 편하더라구. 예전에 만났던 사람처럼. 그러게. 오케이! 기분이다! 친구 된 기념으로 내가 특별히 기프트 하나! 선물? 무슨 선물? 때가 되면 알게 될 거야! 기대해! 드디어 오늘 떠나는 거야? 엔젤! 아무리 시원해도 섭섭한 척 해주면 안 되냐? 내 자랑은 아니지만, 내가 좀 솔직하거든. 치. 자기 맘엔 그렇게 솔직하면서 왜 남의 맘은 몰라줘? 그게 무슨 소리야? 하긴. 러브라는 게 숨긴다고 숨겨지는 게 아니니까. 언젠간 알게 되겠지. 야. 너 자꾸 무슨 소리야. 니 주변에 널 좋아하는 애가 있으니까 좀 알아 달라, 이 소리야. 뭐? 갑자기 그게 무슨. ! 걔 진짜 괜찮은 애거든. 그래서 내가 엔젤 너한테 특별히 기프트로 줄게. 잃어버리면 안 된다! 유 가릿? 무슨 소리야? 알아듣게 좀 얘길 해. 안 그래두 내가 걔 이리로 불렀어. 올 시간 다 됐네. 그럼 나 먼저 갈게. 바이! 내 주변에 날 좋아하는 애가 있다니 그게 무슨. 누나!',\n",
       " '그러나 세종대왕은 부왕이 숨겨둔 책들을 찾아내어 독서를 계속하였다.',\n",
       " '이 충격과 열을 견딜 수 있는 합금기술이 정확하게 지금 준비돼 있느냐 이것도 우리가 한 번 평가를 해봐야 되는 부분이고 또 하나는 어 ~ 제대로 미사일이 이 ~ 탄착지점을 형성할 수 있어야 되느냐 하는 부분입니다. 그런 기술들을 북한이 확보하고 있느냐 하는 부분은 아직은 의문점이 남는 부분입니다. 그래서 이 두 가지 기술이 확인되는 순간 북한에 아이씨비엠 대륙간탄도미사일은 개발됐다 이렇게 평가할 수 있겠습니다. 북한은 이 실험을 한 후에 자신감을 드러내며 추가 도발을 예고했는데요. 김정은 위원장에 말을 들어보시죠. 그런데 북한이 이 신형 로켓엔진을 공개한 시기가 렉스 미국 국무장관이 취임 후 처음으로 한국 중국 일본 이 세 나라를 방문하던 기간이었지 않습니까? 이런 시기에 이런 무력 도발을 한 것 미국을 향한 어떤 메시지를 전달하려고 한 것인가요? 그렇습니다. 그건 뭐 정확한 말씀입니다. 장관이 중국에 가서 왕이 외교부장과 회담을 하는 그때에 북한이 이런 실험을 했거든요. 네. 결국 어 ~ 미국을 겨냥했고 또 중국을 겨냥했다 이렇게 봐야 됩니다. 그래서 지금 이제 트럼프 정부 임기 초반에 미국에 대북압박정책에 북한이 밀리지 않겠다. 또 중국도 미국과 정확하게 문제를 풀어 가는 데 있어서 북한을 고려해라 그렇지 않고는 여러 가지 문제를 또 중국도 안을 수밖에 없다. 이런 차원에서 미국 중국 특히 미국을 겨냥한 에 ~ 그런 실험이었다 이렇게 분명하게 평가할 수 있겠습니다. 네. 북한에 미사일 위협이 점차 커지고 있는데요. 미국과 일본도 이제는 실질적인 위협으로 받아들이는 것 같습니다. 어떻습니까? 네 미국 의회 전문지 더힐에 따르면 트럼프 대통령은 북한이 로켓엔진을 실험한 이후 주말 동안에 북한 미사일에 대해서 논의한 것으로 전해졌습니다. 특히 김정은 위원장에 대해서는 트럼프 대통령이 자주 쓰는 표현으로 매우 매우 나쁘게 행동한다고 말했습니다. 그러면서 동시에 미국에 미사일 방어 시스템을 재점검하도록 지시한 것으로 전해졌는데요. 북한에 미사일 능력이 증강되고 있는 만큼 미국 본토와 동맹국 보호를 위해서 방어 시스템을 손질하겠다는 뜻입니다. 일본 역시 북한에 미사일이 일본 영토에 떨어지는 걸 가정해서 주민 대피 훈련까지 실시했습니다. 민간을 대상으로 한 미사일 대피 훈련은 이번이 처음인데요. 일본 역시 북한에 미사일 위협을 실질적인 위협으로 받아들이는 것으로 볼 수 있겠습니다. 미국 의회와 행정부 내에서는 기존 이 대북정책으로는 북한에 커져가는 군사적 위협을 막을 수 없다 새로운 대북정책이 필요하다는 목소리가 커지고 있습니다. 트럼프 대통령에 말을 들어보시죠. 이런 움직임은 미국 의회에서도 활발한데요. 최근 미 하원이 초강력 대북제재 법안을 새로 발의했다고 하는데요? 네. 미국 하원 외교위원장인 에드 로이스는 지난 이십일일에 새로운 대북제재 법안을 대표 발의했는데요. 내용이 아주 강력합니다. 원유와 석유제품에 수입을 막고 북한에 주요 외화소득원인 노동력 수출을 차단하는 방안들을 담고 있습니다.',\n",
       " '또 거기 이제 해변가에 그 풍경도 풍부하고 그래서 조금 뭐 읽어보고 사진만 봐도 이 북한 금강산이 관광지로 걸 알 수 있을 겁니다. 알겠습니다. 자 요 내용은 여기까지 하구요. 한 가지만 더 질문하고 오늘은 마칠까 합니다. 지금 북한과 미국의 관계가 교착 상태라고 할 수 있는데 어 ~ 이 돌파구가 언제쯤 마련될 거라고 예상하시는지요? 글쎄요. 사실 참 저 공장장님 말씀이 옳은데요. 지금 중국도 원하고 북한도 원하고 있고 러시아도 원하고 있고 남한도 다 이 북한이 개방 되기를 원하고 있습니다. 일본만 지금 이 개방을 원하고 있지 않죠. 왜냐면 이렇게 북한과 남한이 하나가 되서 개방이 됐을 때 이 이런 개방된 한국하고 일본이 경쟁할 수가 없기 때문입니다. 그래도 뭐 일본은 할 수 있는 게 별로 없구요. 지금 문제는 미국 인데요. 뭐 이제 문 대통령이나 중국이나 러시아가 충분히 미국에 압박을 가한다면 가능할 수도 있겠죠. 근데 지금 이 한반도에서 몇천 년 이상 산 것은 한국 민족 아닙니까? 미국은 지금 칠십 년 밖에 이 한반도에 없었습니다. 그냥 쫓아내세요. 자 한국에 어 ~ 조만간 오실 계획이 있으시겠습니다. 그쵸? 오시게 되면 뉴스공장에 꼭 출연해 주시길 바랍니다. 당연히 하시겠지만 예. 다음에 한국에 갈 때는 반드시 공장장님 제가 가겠습니다. 알겠습니다. 오늘 인터뷰 감사합니다. 자 지금까지 투자 전문가 짐 로저스였습니다. 그리고 통역에는 뉴스공장 공식 통역사 홍희연 통역사 였습니다. 네. 불친절한 에이에스 제가 지금 에이에스를 하는 자체가 매우 불친절한 거 같은데 목소리 상태로 봐서 어 ~ 문자가 많이 왔습니다. 이정미 티비 어 ~ 구독자 방송하는 도중에 천 명 넘었고 계속 증가하고 있습니다. 네. 어 ~ 최명수 교수님 그 전에도 방송나왔다 문자 하나 왔습니다. 케이비에스 공감 토론에서 제가 최 교수의 팬이 되었습니다. 그 때도 그러니까 많이 썼습니다. 그러셨겠죠. 그 왜 대구 시내 육백사십구 번 버스 예. 인터넷으로 들으시나봅니다. 예. 대구 육백사십구 번 버스에서 뉴스공장이 나옵니다. 예. 특히 젊은 기사님 잘생겼어요. 여기까지 하겠습니다. 자 어쩌다보니 연속 기획이 되어가고 있습니다. 자 자영업자 문제를 자영업자와 그리고 민생 경제 연구소 에 ~ xx가는 시간입니다. 연구소 소장 안진걸 소장님 나오셨구요. 예. 네. 안녕하십니까? 예. 훨씬 더 중요한 분이죠? 한국 중소 상인 자영업 총 연합회 총 연합회에 반기용 회장님 나오셨습니다. 안녕하십니까 예. 안녕하십니까? 반기용입니다. 네. 첫 방송이 워낙 그 호응이 높아서 어 ~ 계속 모시게 되는데 예. 죄송합니다.',\n",
       " '중립국 감독위원회는 국제 연합군 사령부 군사 정전 위원회 소속으로 북측과 남측의 휴전상태를 감시하는 역할을 맡고 있다.',\n",
       " \"블루스계 권외에서는 엘비스 프레슬리 등의 아티스트가 녹음하게 되는 〈 That's All Right 〉, 〈 My Baby Left Me 〉, 〈 So Glad You're Mine 〉 의 작곡가로 유명하다.\",\n",
       " '팀에게 있어서 2009년 이후 두 번째가 된 클라이맥스 시리즈에서는 퍼스트 스테이지 상대인 요미우리와의 1차전에 5회 대타로 출전하여 동점 적시타를 기록했고 팀은 그 후에 처음으로 파이널 스테이지 진출에 성공했다.',\n",
       " '1999 - 2000 시즌, 키르스텐은 출장 대비 득점수에서 최고를 기록해 EFFIFU 상을 받았다.',\n",
       " '위에서 아래로 \" i \" 번째인 행을 i \" 행, 왼쪽에서 오른쪽으로 \" \" 번째인 열을 \" \" 열이라고 한다.',\n",
       " '1. 상대방을 사기죄로 고소하시길 바랍니다. 2. 고소 후, 합의금명목으로 피해를 회복하시길 바랍니다. 3. 회복되지 않은 피해에 대하여는 민사상 손해배상청구하시길 바랍니다. 4. 핀번호 환전내역 등을 통해 상대방을 특정할 수 있을 것으로 보입니다. 5. 다수 유사 사건 성공적인 수행 경험 있습니다. 제 프로필을 누르시고 후기를 꼭 확인하여 주시길 바랍니다. 제 프로필 상의 전화로 언제든 문의 주시길 바랍니다. 대표변호사인 제가 직접 제 일처럼 사건의 처음부터 끝까지 처리하여 드리겠습니다. 리라 법률사무소 대표변호사 김현중']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
